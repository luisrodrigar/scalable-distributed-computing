{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2. Data Analytics Using PySpark\n",
    "## Scalable and Distributed Computing\n",
    "Sara Dovalo del Río, Alejandra Estrada Sanz and Luis Ángel Rodríguez García"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I\n",
    "#### PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import LongType, TimestampType, IntegerType, DoubleType, StringType\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "from IPython.display import display, Markdown\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "seed_value = 100469000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rateCodeId: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improve_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This DataFrame has **1942420 rows**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_schema = StructType([StructField('VendorID', LongType(), False),\n",
    "                     StructField('tpep_pickup_datetime', TimestampType(), False),\n",
    "                     StructField('tpep_dropoff_datetime', TimestampType(), False),\n",
    "                     StructField('passenger_count', IntegerType(), False),\n",
    "                     StructField('trip_distance', DoubleType(), False),\n",
    "                     StructField('rateCodeId', IntegerType(), False),\n",
    "                     StructField('store_and_fwd_flag', StringType(), False),\n",
    "                     StructField('PULocationID', StringType(), False),\n",
    "                     StructField('DOLocationID', StringType(), False),         \n",
    "                     StructField('payment_type', IntegerType(), False),\n",
    "                     StructField('fare_amount', DoubleType(), False),\n",
    "                     StructField('extra', DoubleType(), False),\n",
    "                     StructField('mta_tax', DoubleType(), False),\n",
    "                     StructField('tip_amount', DoubleType(), False),\n",
    "                     StructField('tolls_amount', DoubleType(), False),\n",
    "                     StructField('improve_surcharge', DoubleType(), False),\n",
    "                     StructField('total_amount', DoubleType(), False)])\n",
    "\n",
    "cab_trips = spark.read \\\n",
    "                .schema(custom_schema) \\\n",
    "                .option('header', 'true') \\\n",
    "                .csv('data/*.csv')\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "cab_trips.printSchema()\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % (cab_trips.count())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the method `cache` to do the optimization of the dataset in order to do the processing faster. Later on, we are going to generate a random sample of the ten percent of the rows without replacemant and select the two first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/17 01:43:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount\n",
      " Schema: VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, rateCodeId, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improve_surcharge, total_amount\n",
      "Expected: improve_surcharge but found: improvement_surcharge\n",
      "CSV file: file:///Users/luisrodrigar/Documents/Statistics%20for%20Data%20Science/Scaled%20and%20Distributed%20Computation/Project/scalable-distributed-computing/Lab%202%20-%20PySpark/data/tripdata_2017-01.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2017, 1, 1, 0, 0, 2), tpep_dropoff_datetime=datetime.datetime(2017, 1, 1, 0, 39, 22), passenger_count=4, trip_distance=7.75, rateCodeId=1, store_and_fwd_flag='N', PULocationID='186', DOLocationID='36', payment_type=1, fare_amount=22.0, extra=0.5, mta_tax=0.5, tip_amount=4.66, tolls_amount=0.0, improve_surcharge=0.3, total_amount=27.96),\n",
       " Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2017, 1, 1, 0, 0, 6), tpep_dropoff_datetime=datetime.datetime(2017, 1, 1, 0, 16, 5), passenger_count=2, trip_distance=2.6, rateCodeId=1, store_and_fwd_flag='N', PULocationID='79', DOLocationID='163', payment_type=1, fare_amount=12.5, extra=0.5, mta_tax=0.5, tip_amount=2.76, tolls_amount=0.0, improve_surcharge=0.3, total_amount=16.56)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/17 07:27:37 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1038600 ms exceeds timeout 120000 ms\n",
      "22/03/17 07:27:37 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "cab_trips.cache()\n",
    "cab_trips.sample(False, 0.1, seed_value).take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of columns incident_id, n_killed, n_injured, n_guns_involved:\")\n",
    "cab_trips.select(\"incident_id\",\"n_killed\",\"n_injured\", \"n_guns_involved\").summary().show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
